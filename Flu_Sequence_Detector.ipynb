{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flu Sequence Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmFkRPKeKZVE",
        "colab_type": "code",
        "outputId": "aea95e71-d75d-4c77-e18b-7e24fce3bb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip install Biopython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/3d/e0c8a993dbea1136be90c31345aefc5babdd5046cd52f81c18fc3fdad865/biopython-1.76-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Biopython) (1.18.3)\n",
            "Installing collected packages: Biopython\n",
            "Successfully installed Biopython-1.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgaWaex9CaG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from Bio import SeqIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "257Ou42JDhQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = [s for s in SeqIO.parse(\"sequence.fasta\", \"fasta\")]\n",
        "metadata = pd.read_csv(r\"https://raw.githubusercontent.com/samarth1107/Virus-stain_prediction/master/metadata.tsv\",sep=\"\\t\",parse_dates=[\"Collection Date\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTsnAeZksaHh",
        "colab_type": "code",
        "outputId": "89f47a9e-2040-42bc-cb13-e18e3f33fe57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "metadata = metadata.sort_values(by=['Collection Date'], ascending=True)\n",
        "metadata.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Sequence Accession</th>\n",
              "      <th>Complete Genome</th>\n",
              "      <th>Segment</th>\n",
              "      <th>Segment Length</th>\n",
              "      <th>Subtype</th>\n",
              "      <th>Collection Date</th>\n",
              "      <th>Host Species</th>\n",
              "      <th>Country</th>\n",
              "      <th>State/Province</th>\n",
              "      <th>Flu Season</th>\n",
              "      <th>Strain Name</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>HA</td>\n",
              "      <td>MF535113</td>\n",
              "      <td>No</td>\n",
              "      <td>4</td>\n",
              "      <td>1701</td>\n",
              "      <td>H1N1</td>\n",
              "      <td>2009-01-01</td>\n",
              "      <td>IRD:Human</td>\n",
              "      <td>India</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>A/Jodhpur/1316/2009</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>HA</td>\n",
              "      <td>HM204566</td>\n",
              "      <td>No</td>\n",
              "      <td>4</td>\n",
              "      <td>1769</td>\n",
              "      <td>H1N1</td>\n",
              "      <td>2009-06-01</td>\n",
              "      <td>IRD:Human</td>\n",
              "      <td>India</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>A/Delhi/NIV57/2009</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>HA</td>\n",
              "      <td>HM204567</td>\n",
              "      <td>No</td>\n",
              "      <td>4</td>\n",
              "      <td>1709</td>\n",
              "      <td>H1N1</td>\n",
              "      <td>2009-06-01</td>\n",
              "      <td>IRD:Human</td>\n",
              "      <td>India</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>A/Mum/NIV261/2009</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>HA</td>\n",
              "      <td>CY075901</td>\n",
              "      <td>No</td>\n",
              "      <td>4</td>\n",
              "      <td>1760</td>\n",
              "      <td>H1N1</td>\n",
              "      <td>2009-06-21</td>\n",
              "      <td>IRD:Human</td>\n",
              "      <td>India</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>A/Pune/NIV161/2009</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>HA</td>\n",
              "      <td>CY075914</td>\n",
              "      <td>No</td>\n",
              "      <td>4</td>\n",
              "      <td>1756</td>\n",
              "      <td>H1N1</td>\n",
              "      <td>2009-06-27</td>\n",
              "      <td>IRD:Human</td>\n",
              "      <td>India</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>-N/A-</td>\n",
              "      <td>A/Che/NIV246/2009</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Name Sequence Accession  ...          Strain Name  Unnamed: 12\n",
              "430   HA           MF535113  ...  A/Jodhpur/1316/2009          NaN\n",
              "125   HA           HM204566  ...   A/Delhi/NIV57/2009          NaN\n",
              "489   HA           HM204567  ...    A/Mum/NIV261/2009          NaN\n",
              "504   HA           CY075901  ...   A/Pune/NIV161/2009          NaN\n",
              "86    HA           CY075914  ...    A/Che/NIV246/2009          NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMUgaJkKs8wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata.iloc[542:,:]  # data for testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRb6uEciN8m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata = metadata[metadata['Host Species'] == 'IRD:Human']\n",
        "\n",
        "#Training data\n",
        "training_metadata = metadata[metadata['Collection Date'] < datetime(2018, 1, 1)]\n",
        "training_idxs = [i for i, s in enumerate(sequences) if s.id[3:11] in training_metadata['Sequence Accession'].values]\n",
        "training_sequences = [sequences[i][30:1737] for i in training_idxs]\n",
        "\n",
        "#Testing data\n",
        "test_metadata = metadata[metadata['Collection Date'] >= datetime(2018, 1, 1)]\n",
        "test_idxs = [i for i, s in enumerate(sequences) if s.id[3:11] in test_metadata['Sequence Accession'].values]\n",
        "test_sequences = [sequences[i][30:1737] for i in test_idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWJaT59DOjbn",
        "colab_type": "code",
        "outputId": "679d24c8-6116-4b79-ac41-7caed5724a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(len(training_idxs))\n",
        "print(len(test_idxs))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "542\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0PYygWd4q8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from copy import deepcopy\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "\n",
        "def encode_array(sequences):\n",
        "\n",
        "    #To find length of biggest sequence\n",
        "    total_sequence = len(sequences)\n",
        "    max_size_sequence = max(Counter([len(s) for s in sequences]).keys())\n",
        "\n",
        "    #To find common acid that is presant in all amino acids\n",
        "    common_amino_acid = set()\n",
        "    for s in sequences:\n",
        "        common_amino_acid = common_amino_acid.union(set(s))\n",
        "    \n",
        "    #To create one-hot encoding of amino acids that is common in all\n",
        "    one_hot  = LabelBinarizer()\n",
        "    one_hot.fit(list(common_amino_acid))\n",
        "    total_common_amino_acid = len(common_amino_acid)\n",
        "\n",
        "    #To convert sequence into array of character or amino_acids\n",
        "    padded_sequences = deepcopy(sequences)\n",
        "\n",
        "    #Padding\n",
        "    for s in padded_sequences:\n",
        "        while len(s) < max_size_sequence:s.seq+='-'\n",
        "\n",
        "    #Sequence after padding\n",
        "    seq_array = np.chararray(shape=(total_sequence,max_size_sequence),unicode=True)\n",
        "    for i, seq in enumerate(padded_sequences):\n",
        "        seq_array[i, :] = list(seq)\n",
        "\n",
        "    encoded_array = np.zeros(shape=(total_sequence, max_size_sequence*total_common_amino_acid))\n",
        "\n",
        "    for i in range(max_size_sequence):\n",
        "        encoded_array[:,i*total_common_amino_acid:(i+1)*total_common_amino_acid] = one_hot.transform(seq_array[:, i])\n",
        "\n",
        "    return encoded_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wugGqBOE455v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_array = encode_array(sequences)\n",
        "training_array = sequence_array[training_idxs]\n",
        "test_array = sequence_array[test_idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQU6ieBL5FLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0f2357d6-1ae1-48b1-ba35-5c9da9ba462d"
      },
      "source": [
        "print(sequence_array.shape)\n",
        "print(training_array.shape)\n",
        "print(test_array.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(551, 10626)\n",
            "(542, 10626)\n",
            "(9, 10626)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgtPOqMWaQCy",
        "colab_type": "code",
        "outputId": "aaf09a2a-69eb-4b3e-d428-d740b6f81920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!pip install --upgrade keras"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q33V50w5VjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f058fafb-3992-4505-b1d0-539558769097"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Lambda, Dropout\n",
        "from keras.models import Model, model_from_json\n",
        "from keras import backend as K\n",
        "from keras import objectives\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxssUkl6VWC",
        "colab_type": "code",
        "outputId": "9a14a495-f3c8-4540-ff2f-928e346f23bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set up VAE.\n",
        "with tf.device('/gpu:0'):\n",
        "\n",
        "    #parameters of model\n",
        "    intermediate_dim = 1000\n",
        "    encoding_dim = 3\n",
        "    latent_dim = encoding_dim\n",
        "    epsilon_std = 1.0\n",
        "    nb_epoch = 250\n",
        "\n",
        "    x = Input(shape=(training_array.shape[1],))\n",
        "    z_mean = Dense(latent_dim)(x)\n",
        "    z_log_var = Dense(latent_dim)(x)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = K.random_normal(shape=(latent_dim, ), mean=0.,\n",
        "                                  stddev=epsilon_std)\n",
        "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "    #loss function\n",
        "    def vae_loss(x, x_decoded_mean):\n",
        "        xent_loss = training_array.shape[1] * objectives.binary_crossentropy(x, x_decoded_mean)\n",
        "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return xent_loss + kl_loss\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "    x_decoded_mean = Dense(training_array.shape[1], activation='sigmoid')(z_mean)\n",
        "\n",
        "    #variational autoencoder\n",
        "    vae = Model(x, x_decoded_mean)\n",
        "    vae.compile(optimizer='adam', loss=vae_loss)\n",
        "\n",
        "    # build a model to project inputs on the latent space\n",
        "    encoder = Model(x, z_mean)\n",
        "    encoder_var = Model(x, z_log_var)\n",
        "\n",
        "    #train test split\n",
        "    x_train, x_test = train_test_split(training_array)\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=2)\n",
        "\n",
        "\n",
        "    # build the decoder\n",
        "    encoded_input = Input(shape=(encoding_dim,))\n",
        "    # retrieve the last layer of the autoencoder model\n",
        "    decoder_layer = vae.layers[-1]\n",
        "    # create the decoder model\n",
        "    decoder = Model(inputs=encoded_input, outputs=decoder_layer(encoded_input))\n",
        "\n",
        "\n",
        "    # Train the VAE to learn weights\n",
        "    vae.fit(x_train, x_train,\n",
        "            shuffle=True,\n",
        "            epochs=nb_epoch,\n",
        "            validation_data=(x_test, x_test),\n",
        "            callbacks=[early_stopping],\n",
        "           )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 406 samples, validate on 136 samples\n",
            "Epoch 1/250\n",
            "406/406 [==============================] - 2s 4ms/step - loss: 7161.9321 - val_loss: 6268.2201\n",
            "Epoch 2/250\n",
            "406/406 [==============================] - 0s 184us/step - loss: 4718.6279 - val_loss: 3213.7021\n",
            "Epoch 3/250\n",
            "406/406 [==============================] - 0s 181us/step - loss: 2653.7828 - val_loss: 2040.7236\n",
            "Epoch 4/250\n",
            "406/406 [==============================] - 0s 192us/step - loss: 1876.9937 - val_loss: 1630.4732\n",
            "Epoch 5/250\n",
            "406/406 [==============================] - 0s 205us/step - loss: 1574.3136 - val_loss: 1426.5701\n",
            "Epoch 6/250\n",
            "406/406 [==============================] - 0s 189us/step - loss: 1409.7659 - val_loss: 1300.4684\n",
            "Epoch 7/250\n",
            "406/406 [==============================] - 0s 198us/step - loss: 1298.2581 - val_loss: 1206.3087\n",
            "Epoch 8/250\n",
            "406/406 [==============================] - 0s 194us/step - loss: 1216.9778 - val_loss: 1134.8979\n",
            "Epoch 9/250\n",
            "406/406 [==============================] - 0s 184us/step - loss: 1152.4098 - val_loss: 1078.0724\n",
            "Epoch 10/250\n",
            "406/406 [==============================] - 0s 185us/step - loss: 1099.9896 - val_loss: 1029.5882\n",
            "Epoch 11/250\n",
            "406/406 [==============================] - 0s 184us/step - loss: 1054.9519 - val_loss: 988.6667\n",
            "Epoch 12/250\n",
            "406/406 [==============================] - 0s 186us/step - loss: 1017.3158 - val_loss: 952.9945\n",
            "Epoch 13/250\n",
            "406/406 [==============================] - 0s 194us/step - loss: 983.9689 - val_loss: 922.1262\n",
            "Epoch 14/250\n",
            "406/406 [==============================] - 0s 200us/step - loss: 954.8214 - val_loss: 893.8392\n",
            "Epoch 15/250\n",
            "406/406 [==============================] - 0s 195us/step - loss: 928.7147 - val_loss: 868.8714\n",
            "Epoch 16/250\n",
            "406/406 [==============================] - 0s 192us/step - loss: 905.1117 - val_loss: 847.3633\n",
            "Epoch 17/250\n",
            "406/406 [==============================] - 0s 189us/step - loss: 884.5781 - val_loss: 826.2869\n",
            "Epoch 18/250\n",
            "406/406 [==============================] - 0s 204us/step - loss: 862.9208 - val_loss: 807.5571\n",
            "Epoch 19/250\n",
            "406/406 [==============================] - 0s 189us/step - loss: 845.3380 - val_loss: 790.1272\n",
            "Epoch 20/250\n",
            "406/406 [==============================] - 0s 185us/step - loss: 830.5539 - val_loss: 774.8580\n",
            "Epoch 21/250\n",
            "406/406 [==============================] - 0s 186us/step - loss: 814.9950 - val_loss: 764.7748\n",
            "Epoch 22/250\n",
            "406/406 [==============================] - 0s 199us/step - loss: 802.1323 - val_loss: 752.7880\n",
            "Epoch 23/250\n",
            "406/406 [==============================] - 0s 190us/step - loss: 792.3615 - val_loss: 746.5286\n",
            "Epoch 24/250\n",
            "406/406 [==============================] - 0s 196us/step - loss: 785.1213 - val_loss: 729.9121\n",
            "Epoch 25/250\n",
            "406/406 [==============================] - 0s 190us/step - loss: 775.6489 - val_loss: 717.5055\n",
            "Epoch 26/250\n",
            "406/406 [==============================] - 0s 205us/step - loss: 762.3568 - val_loss: 705.6945\n",
            "Epoch 27/250\n",
            "406/406 [==============================] - 0s 203us/step - loss: 752.6263 - val_loss: 698.7824\n",
            "Epoch 28/250\n",
            "406/406 [==============================] - 0s 197us/step - loss: 740.2631 - val_loss: 686.1408\n",
            "Epoch 29/250\n",
            "406/406 [==============================] - 0s 204us/step - loss: 726.2135 - val_loss: 671.9427\n",
            "Epoch 30/250\n",
            "406/406 [==============================] - 0s 195us/step - loss: 713.4705 - val_loss: 661.2809\n",
            "Epoch 31/250\n",
            "406/406 [==============================] - 0s 193us/step - loss: 708.7137 - val_loss: 651.3190\n",
            "Epoch 32/250\n",
            "406/406 [==============================] - 0s 193us/step - loss: 691.6319 - val_loss: 641.2509\n",
            "Epoch 33/250\n",
            "406/406 [==============================] - 0s 191us/step - loss: 680.7920 - val_loss: 631.4832\n",
            "Epoch 34/250\n",
            "406/406 [==============================] - 0s 184us/step - loss: 671.0766 - val_loss: 621.0862\n",
            "Epoch 35/250\n",
            "406/406 [==============================] - 0s 198us/step - loss: 659.7415 - val_loss: 611.3861\n",
            "Epoch 36/250\n",
            "406/406 [==============================] - 0s 199us/step - loss: 648.1946 - val_loss: 600.5518\n",
            "Epoch 37/250\n",
            "406/406 [==============================] - 0s 192us/step - loss: 638.0517 - val_loss: 591.0468\n",
            "Epoch 38/250\n",
            "406/406 [==============================] - 0s 186us/step - loss: 626.4718 - val_loss: 579.5914\n",
            "Epoch 39/250\n",
            "406/406 [==============================] - 0s 194us/step - loss: 614.9346 - val_loss: 570.4973\n",
            "Epoch 40/250\n",
            "406/406 [==============================] - 0s 195us/step - loss: 605.7363 - val_loss: 561.8947\n",
            "Epoch 41/250\n",
            "406/406 [==============================] - 0s 190us/step - loss: 596.3275 - val_loss: 553.2271\n",
            "Epoch 42/250\n",
            "406/406 [==============================] - 0s 197us/step - loss: 587.9445 - val_loss: 547.0182\n",
            "Epoch 43/250\n",
            "406/406 [==============================] - 0s 195us/step - loss: 583.3687 - val_loss: 543.0802\n",
            "Epoch 44/250\n",
            "406/406 [==============================] - 0s 196us/step - loss: 577.2849 - val_loss: 537.7760\n",
            "Epoch 45/250\n",
            "406/406 [==============================] - 0s 191us/step - loss: 574.0997 - val_loss: 531.4565\n",
            "Epoch 46/250\n",
            "406/406 [==============================] - 0s 183us/step - loss: 570.7156 - val_loss: 532.5807\n",
            "Epoch 47/250\n",
            "406/406 [==============================] - 0s 207us/step - loss: 569.5462 - val_loss: 532.1267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDGETdiUyq8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing of encoder and decoder\n",
        "test_embeddings_mean = encoder.predict(test_array)\n",
        "test_binary_mean = decoder.predict(test_embeddings_mean)\n",
        "for i in range(len(test_binary_mean)):\n",
        "  test_binary_mean[i] = test_binary_mean[i].round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6DKMG9QBQPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def right_pad(sequences):\n",
        "    padded_sequences = deepcopy(sequences)\n",
        "    seq_lengths = compute_seq_lengths(sequences)\n",
        "\n",
        "    for s in padded_sequences:\n",
        "        while len(s) < max(seq_lengths.keys()):\n",
        "            s.seq += '*'\n",
        "    return padded_sequences\n",
        "\n",
        "\n",
        "def compute_seq_lengths(sequences):\n",
        "    seq_lengths = [len(s) for s in sequences]\n",
        "    seq_lengths = Counter(seq_lengths)\n",
        "    return seq_lengths\n",
        "\n",
        "\n",
        "def seq2chararray(sequences):\n",
        "    padded_sequences = right_pad(sequences)\n",
        "    seq_lengths = compute_seq_lengths(sequences)\n",
        "    char_array = np.chararray(shape=(len(sequences), max(seq_lengths.keys())),\n",
        "                              unicode=True)\n",
        "    for i, seq in enumerate(padded_sequences):\n",
        "        char_array[i, :] = list(seq)\n",
        "    return char_array\n",
        "\n",
        "\n",
        "def compute_alphabet(sequences):\n",
        "    alphabet = set()\n",
        "    for s in sequences:\n",
        "        alphabet = alphabet.union(set(s))\n",
        "\n",
        "    return alphabet\n",
        "\n",
        "\n",
        "def binary2chararray(sequences, binary_array):\n",
        "\n",
        "    alphabet = compute_alphabet(sequences)\n",
        "    seq_lengths = compute_seq_lengths(sequences)\n",
        "    seq_array = seq2chararray(sequences)\n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(list(alphabet))\n",
        "\n",
        "    char_array = np.chararray(shape=(len(binary_array),\n",
        "                              max(seq_lengths.keys())), unicode=True)\n",
        "\n",
        "    for i in range(seq_array.shape[1]):\n",
        "        char_array[:, i] = lb.inverse_transform(binary_array[:, i*len(alphabet):(i+1)*len(alphabet)])\n",
        "\n",
        "    return char_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-mtlmC0Culn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "a88f1bea-79a0-44b3-9cc0-6b8f5719f48e"
      },
      "source": [
        "result=binary2chararray(sequences,test_binary_mean)\n",
        "loop=-1\n",
        "for seq in sequences[542:]:\n",
        "  positive = 0\n",
        "  negative = 0\n",
        "  loop+=1\n",
        "  for i in range(len(seq)):\n",
        "    if (seq.seq)[i]==result[loop][i]:\n",
        "      positive+=1\n",
        "    else:\n",
        "      negative+=1\n",
        "  print(positive*100/len(seq))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.47089947089947\n",
            "98.88300999412111\n",
            "99.05937683715462\n",
            "98.41269841269842\n",
            "99.23574368018812\n",
            "99.3533215755438\n",
            "97.03026841804683\n",
            "99.00058788947678\n",
            "98.77049180327869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cAT4d3Gf_ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = encoder.predict(training_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlGAhwFmgZ-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_lstm = x_train.reshape(542 ,1, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JORFST3h055",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_lstm=[]\n",
        "for i in range(len(x_train)-5):\n",
        "  temp=[]\n",
        "  for batch in range(i,i+5):\n",
        "    temp.append(x_train[i])\n",
        "  x_train_lstm.append(temp)\n",
        "x_train_lstm=np.array(x_train_lstm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2fy4lHfh5bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f077ff6-3f45-4b80-df42-3464ef5e883d"
      },
      "source": [
        "x_train_lstm.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(537, 5, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJP7VwafdE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "b3fab7ee-aeab-4650-9f70-35f9e495e4d8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=10, activation='relu', input_shape=(5,3)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 10)                560       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 990\n",
            "Trainable params: 990\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOjOdTEUiapd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "8cecbb2d-26ea-4dae-ea38-e4563944f910"
      },
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.fit(x_train_lstm[0:],\n",
        "          just[5:],\n",
        "          epochs=3)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "537/537 [==============================] - 0s 897us/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "537/537 [==============================] - 0s 305us/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "537/537 [==============================] - 0s 316us/step - loss: nan - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7c2aef3e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARcCGrV1jN70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b06c1c7a-6755-415b-fea6-f2b62747872f"
      },
      "source": [
        "x_train_lstm[0:].shape"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(537, 5, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP8PzNe1i1ZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb39406e-3a15-4088-db1b-61ac4bc94cad"
      },
      "source": [
        "just = []\n",
        "for i in x_train:\n",
        "  just.append(np.sum(i))\n",
        "just = np.array(just)\n",
        "just[5:].shape"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(537,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    }
  ]
}